{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3bf801f",
   "metadata": {},
   "source": [
    "# üéØ Sentiment Analysis - Twitter Dataset\n",
    "_A project to classify sentiments from tweets using Naive Bayes and TF-IDF._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f59a6",
   "metadata": {},
   "source": [
    "## üìÇ Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Project Objective](#project-objective)\n",
    "3. [Data Preparation](#data-preparation)\n",
    "4. [Pipeline Development](#pipeline-development)\n",
    "5. [Model Development](#model-development)\n",
    "6. [Validation Data Testing](#validation-testing)\n",
    "7. [Single Input Prediction](#single-input-prediction)\n",
    "8. [Conclusion and Next Steps](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abccf583",
   "metadata": {},
   "source": [
    "## üìñ Introduction <a name=\"introduction\"></a>\n",
    "In this project, we build a sentiment analysis model to classify tweets as Positive or Negative using the Twitter dataset.\n",
    "\n",
    "We use natural language processing (NLP) techniques to clean, vectorize, and classify tweets, and we evaluate the model using both training and validation datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dde84d",
   "metadata": {},
   "source": [
    "## üéØ Project Objective <a name=\"project-objective\"></a>\n",
    "> - Build a text classification model using Naive Bayes.  \n",
    "> - Preprocess tweets using a custom pipeline.  \n",
    "> - Evaluate the model using real validation data and test on single inputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502ad10",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Data Preparation <a name=\"data-preparation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed9cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596518ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Load Dataset\n",
    "data = pd.read_csv(\"twitter_training.csv\", header=None)\n",
    "data.columns = ['Tweet_ID', 'Entity', 'Sentiment', 'Review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db7f44a",
   "metadata": {},
   "source": [
    "Drop entries where sentiment is either irrelevant or neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7c7a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                             Review\n",
       "0  Positive  im getting on borderlands and i will murder yo...\n",
       "1  Positive  I am coming to the borders and I will kill you...\n",
       "2  Positive  im getting on borderlands and i will kill you ...\n",
       "3  Positive  im coming on borderlands and i will murder you...\n",
       "4  Positive  im getting on borderlands 2 and i will murder ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üßπ Clean Dataset\n",
    "data.dropna(inplace=True)\n",
    "data = data[data['Sentiment'] != 'Irrelevant']\n",
    "data = data[data['Sentiment'] != 'Neutral']\n",
    "data.drop(['Tweet_ID', 'Entity'], axis=1, inplace=True)\n",
    "\n",
    "# ‚úÖ Check Cleaned Data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d4552",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Pipeline Development <a name=\"pipeline-development\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff9870",
   "metadata": {},
   "source": [
    "The TextPreprocessor transformer removes common English stopwords from text data, tokenizes each sentence, and returns the cleaned text while the pipeline  first removes stopwords from the text using TextPreprocessor. Then, it converts the cleaned text into numerical features using TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0134e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to remove stopwords\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.apply(self._remove_stopwords)\n",
    "\n",
    "    def _remove_stopwords(self, sentence):\n",
    "        tokens = self.tokenizer.tokenize(sentence)\n",
    "        filtered = [word for word in tokens if word.lower() not in self.stopwords]\n",
    "        return ' '.join(filtered)\n",
    "\n",
    "# Build the pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('preprocess', TextPreprocessor()),\n",
    "    ('tfidf', TfidfVectorizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef0152",
   "metadata": {},
   "source": [
    "## ü§ñ Model Development <a name=\"model-development\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00745e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.92      0.90      4467\n",
      "    Positive       0.91      0.86      0.88      4136\n",
      "\n",
      "    accuracy                           0.89      8603\n",
      "   macro avg       0.89      0.89      0.89      8603\n",
      "weighted avg       0.89      0.89      0.89      8603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Feature Extraction\n",
    "X = text_pipeline.fit_transform(data['Review'])\n",
    "y = data['Sentiment']\n",
    "\n",
    "# üîÄ Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# üß† Model Training\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# üìä Evaluate on Test Set\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea3f28",
   "metadata": {},
   "source": [
    "## üß™ Validation Data Testing <a name=\"validation-testing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de5543",
   "metadata": {},
   "source": [
    "Load the validation data and preprocess it. Then, we use the trained model to predict the sentiment of each tweet in the validation set.\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab548b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.95      0.94       266\n",
      "    Positive       0.95      0.93      0.94       277\n",
      "\n",
      "    accuracy                           0.94       543\n",
      "   macro avg       0.94      0.94      0.94       543\n",
      "weighted avg       0.94      0.94      0.94       543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üìÇ Load Validation Dataset\n",
    "val_data = pd.read_csv(\"twitter_validation.csv\", header=None)\n",
    "\n",
    "# üßπ Preprocess Validation Data\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    df.columns = ['Tweet_ID', 'Entity', 'Sentiment', 'Review']\n",
    "    df.dropna(inplace=True)\n",
    "    df = df[df['Sentiment'] != 'Irrelevant']\n",
    "    df = df[df['Sentiment'] != 'Neutral']\n",
    "    df.drop(['Tweet_ID', 'Entity'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "val_data = preprocess_data(val_data)\n",
    "\n",
    "# üîÑ Transform Validation Data\n",
    "val_X = text_pipeline.transform(val_data['Review'])\n",
    "val_y = val_data['Sentiment']\n",
    "\n",
    "# üîÆ Predict and Evaluate\n",
    "val_y_pred = model.predict(val_X)\n",
    "print(classification_report(val_y, val_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d9a85",
   "metadata": {},
   "source": [
    "## üìù Single Input Prediction <a name=\"single-input-prediction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f64c32c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It was an amazing experience all round.\n",
      "Predicted Sentiment: ['Positive']\n"
     ]
    }
   ],
   "source": [
    "# üé§ Predict Sentiment on New Input\n",
    "user_review = pd.Series(str(input(\"Type a review to predict its sentiment: \")))\n",
    "\n",
    "new_review = text_pipeline.transform(user_review)\n",
    "print(\"Review:\", user_review.values[0])\n",
    "print(\"Predicted Sentiment:\", model.predict(new_review))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a572e3d",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusion and Next Steps <a name=\"conclusion\"></a>\n",
    "> - Successfully built a sentiment analysis model using Naive Bayes and TF-IDF.  \n",
    "> - Evaluated model on training and validation data.  \n",
    "> - Enabled real-time single input prediction.  \n",
    "> - Future improvements: try deep learning models, handle sarcasm, or integrate real-time Twitter API.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
